{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-30T16:03:39.653398Z","iopub.execute_input":"2023-11-30T16:03:39.654519Z","iopub.status.idle":"2023-11-30T16:03:39.667159Z","shell.execute_reply.started":"2023-11-30T16:03:39.654423Z","shell.execute_reply":"2023-11-30T16:03:39.666086Z"},"trusted":true},"execution_count":98,"outputs":[{"name":"stdout","text":"/kaggle/input/crowdflower-search-relevance/train.csv.zip\n/kaggle/input/crowdflower-search-relevance/sampleSubmission.csv.zip\n/kaggle/input/crowdflower-search-relevance/test.csv.zip\n","output_type":"stream"}]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/crowdflower-search-relevance/train.csv.zip')\ntest = pd.read_csv('/kaggle/input/crowdflower-search-relevance/test.csv.zip')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T16:03:39.669238Z","iopub.execute_input":"2023-11-30T16:03:39.669561Z","iopub.status.idle":"2023-11-30T16:03:40.159570Z","shell.execute_reply.started":"2023-11-30T16:03:39.669520Z","shell.execute_reply":"2023-11-30T16:03:40.158568Z"},"trusted":true},"execution_count":99,"outputs":[{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"   id                      query  \\\n0   1  bridal shower decorations   \n1   2       led christmas lights   \n2   4                  projector   \n3   5                  wine rack   \n4   7                 light bulb   \n\n                                       product_title  \\\n0        Accent Pillow with Heart Design - Red/Black   \n1  Set of 10 Battery Operated Multi LED Train Chr...   \n2         ViewSonic Pro8200 DLP Multimedia Projector   \n3  Concept Housewares WR-44526 Solid-Wood Ceiling...   \n4  Wintergreen Lighting Christmas LED Light Bulb ...   \n\n                                 product_description  median_relevance  \\\n0  Red satin accent pillow embroidered with a hea...                 1   \n1  Set of 10 Battery Operated Train Christmas Lig...                 4   \n2                                                NaN                 4   \n3  Like a silent and sturdy tree, the Southern En...                 4   \n4  WTGR1011\\nFeatures\\nNickel base, 60,000 averag...                 2   \n\n   relevance_variance  \n0               0.000  \n1               0.000  \n2               0.471  \n3               0.000  \n4               0.471  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>query</th>\n      <th>product_title</th>\n      <th>product_description</th>\n      <th>median_relevance</th>\n      <th>relevance_variance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>bridal shower decorations</td>\n      <td>Accent Pillow with Heart Design - Red/Black</td>\n      <td>Red satin accent pillow embroidered with a hea...</td>\n      <td>1</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>led christmas lights</td>\n      <td>Set of 10 Battery Operated Multi LED Train Chr...</td>\n      <td>Set of 10 Battery Operated Train Christmas Lig...</td>\n      <td>4</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>projector</td>\n      <td>ViewSonic Pro8200 DLP Multimedia Projector</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>0.471</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>wine rack</td>\n      <td>Concept Housewares WR-44526 Solid-Wood Ceiling...</td>\n      <td>Like a silent and sturdy tree, the Southern En...</td>\n      <td>4</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>light bulb</td>\n      <td>Wintergreen Lighting Christmas LED Light Bulb ...</td>\n      <td>WTGR1011\\nFeatures\\nNickel base, 60,000 averag...</td>\n      <td>2</td>\n      <td>0.471</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T16:03:40.161797Z","iopub.execute_input":"2023-11-30T16:03:40.162363Z","iopub.status.idle":"2023-11-30T16:03:40.183661Z","shell.execute_reply.started":"2023-11-30T16:03:40.162312Z","shell.execute_reply":"2023-11-30T16:03:40.181969Z"},"trusted":true},"execution_count":100,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 10158 entries, 0 to 10157\nData columns (total 6 columns):\n #   Column               Non-Null Count  Dtype  \n---  ------               --------------  -----  \n 0   id                   10158 non-null  int64  \n 1   query                10158 non-null  object \n 2   product_title        10158 non-null  object \n 3   product_description  7714 non-null   object \n 4   median_relevance     10158 non-null  int64  \n 5   relevance_variance   10158 non-null  float64\ndtypes: float64(1), int64(2), object(3)\nmemory usage: 476.3+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"test.info()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T16:03:40.185380Z","iopub.execute_input":"2023-11-30T16:03:40.185771Z","iopub.status.idle":"2023-11-30T16:03:40.213984Z","shell.execute_reply.started":"2023-11-30T16:03:40.185730Z","shell.execute_reply":"2023-11-30T16:03:40.212713Z"},"trusted":true},"execution_count":101,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 22513 entries, 0 to 22512\nData columns (total 4 columns):\n #   Column               Non-Null Count  Dtype \n---  ------               --------------  ----- \n 0   id                   22513 non-null  int64 \n 1   query                22513 non-null  object\n 2   product_title        22513 non-null  object\n 3   product_description  17086 non-null  object\ndtypes: int64(1), object(3)\nmemory usage: 703.7+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T16:03:40.217777Z","iopub.execute_input":"2023-11-30T16:03:40.218168Z","iopub.status.idle":"2023-11-30T16:03:40.248338Z","shell.execute_reply.started":"2023-11-30T16:03:40.218117Z","shell.execute_reply":"2023-11-30T16:03:40.247126Z"},"trusted":true},"execution_count":102,"outputs":[{"execution_count":102,"output_type":"execute_result","data":{"text/plain":"                 id  median_relevance  relevance_variance\ncount  10158.000000      10158.000000        10158.000000\nmean   16353.103071          3.309805            0.377863\nstd     9447.106683          0.980666            0.389707\nmin        1.000000          1.000000            0.000000\n25%     8078.750000          3.000000            0.000000\n50%    16349.500000          4.000000            0.471000\n75%    24570.750000          4.000000            0.471000\nmax    32668.000000          4.000000            1.470000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>median_relevance</th>\n      <th>relevance_variance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>10158.000000</td>\n      <td>10158.000000</td>\n      <td>10158.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>16353.103071</td>\n      <td>3.309805</td>\n      <td>0.377863</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>9447.106683</td>\n      <td>0.980666</td>\n      <td>0.389707</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>8078.750000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>16349.500000</td>\n      <td>4.000000</td>\n      <td>0.471000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>24570.750000</td>\n      <td>4.000000</td>\n      <td>0.471000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>32668.000000</td>\n      <td>4.000000</td>\n      <td>1.470000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train['query'].map(lambda x:len(x.split())).value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T16:03:40.249948Z","iopub.execute_input":"2023-11-30T16:03:40.250380Z","iopub.status.idle":"2023-11-30T16:03:40.272814Z","shell.execute_reply.started":"2023-11-30T16:03:40.250344Z","shell.execute_reply":"2023-11-30T16:03:40.271531Z"},"trusted":true},"execution_count":103,"outputs":[{"execution_count":103,"output_type":"execute_result","data":{"text/plain":"2    5379\n3    2819\n4     925\n1     885\n6      81\n5      69\nName: query, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"train['product_title'].map(lambda x:len(x.split())).value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T16:03:40.274563Z","iopub.execute_input":"2023-11-30T16:03:40.274917Z","iopub.status.idle":"2023-11-30T16:03:40.305458Z","shell.execute_reply.started":"2023-11-30T16:03:40.274880Z","shell.execute_reply":"2023-11-30T16:03:40.302915Z"},"trusted":true},"execution_count":104,"outputs":[{"execution_count":104,"output_type":"execute_result","data":{"text/plain":"7     1288\n6     1284\n8     1183\n9     1122\n5     1002\n10     880\n11     744\n12     678\n4      550\n13     453\n14     289\n15     181\n3      174\n17      78\n16      66\n2       51\n18      25\n19      24\n20      15\n24      11\n21       7\n25       7\n27       6\n26       6\n22       6\n28       6\n23       6\n29       4\n1        2\n46       2\n32       2\n38       1\n44       1\n34       1\n31       1\n43       1\n41       1\nName: product_title, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"split = int(len(train)*0.8)\ntrain_0, dev = train[:split], train[split:]","metadata":{"execution":{"iopub.status.busy":"2023-11-30T16:03:40.307567Z","iopub.execute_input":"2023-11-30T16:03:40.307958Z","iopub.status.idle":"2023-11-30T16:03:40.315216Z","shell.execute_reply.started":"2023-11-30T16:03:40.307915Z","shell.execute_reply":"2023-11-30T16:03:40.314015Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clean_train_1 = train_0[train_0.relevance_variance <1].copy()\nclean_train_2 = train_0[train_0.relevance_variance <0.50].copy()\ndev.describe()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T16:03:40.316814Z","iopub.execute_input":"2023-11-30T16:03:40.317097Z","iopub.status.idle":"2023-11-30T16:03:40.350455Z","shell.execute_reply.started":"2023-11-30T16:03:40.317052Z","shell.execute_reply":"2023-11-30T16:03:40.349207Z"},"trusted":true},"execution_count":106,"outputs":[{"execution_count":106,"output_type":"execute_result","data":{"text/plain":"                 id  median_relevance  relevance_variance\ncount   2032.000000       2032.000000         2032.000000\nmean   29406.014764          3.319390            0.361364\nstd     1870.217123          0.972218            0.379619\nmin    26215.000000          1.000000            0.000000\n25%    27777.250000          3.000000            0.000000\n50%    29410.000000          4.000000            0.471000\n75%    31014.750000          4.000000            0.471000\nmax    32668.000000          4.000000            1.470000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>median_relevance</th>\n      <th>relevance_variance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2032.000000</td>\n      <td>2032.000000</td>\n      <td>2032.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>29406.014764</td>\n      <td>3.319390</td>\n      <td>0.361364</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1870.217123</td>\n      <td>0.972218</td>\n      <td>0.379619</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>26215.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>27777.250000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>29410.000000</td>\n      <td>4.000000</td>\n      <td>0.471000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>31014.750000</td>\n      <td>4.000000</td>\n      <td>0.471000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>32668.000000</td>\n      <td>4.000000</td>\n      <td>1.470000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"clean_train_1.describe()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T16:03:40.352279Z","iopub.execute_input":"2023-11-30T16:03:40.352891Z","iopub.status.idle":"2023-11-30T16:03:40.377512Z","shell.execute_reply.started":"2023-11-30T16:03:40.352848Z","shell.execute_reply":"2023-11-30T16:03:40.376541Z"},"trusted":true},"execution_count":107,"outputs":[{"execution_count":107,"output_type":"execute_result","data":{"text/plain":"                 id  median_relevance  relevance_variance\ncount   7558.000000       7558.000000         7558.000000\nmean   13074.201111          3.344403            0.321038\nstd     7571.543134          0.974908            0.332482\nmin        1.000000          1.000000            0.000000\n25%     6496.500000          3.000000            0.000000\n50%    13129.000000          4.000000            0.471000\n75%    19563.250000          4.000000            0.471000\nmax    26208.000000          4.000000            0.980000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>median_relevance</th>\n      <th>relevance_variance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>7558.000000</td>\n      <td>7558.000000</td>\n      <td>7558.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>13074.201111</td>\n      <td>3.344403</td>\n      <td>0.321038</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>7571.543134</td>\n      <td>0.974908</td>\n      <td>0.332482</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>6496.500000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>13129.000000</td>\n      <td>4.000000</td>\n      <td>0.471000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>19563.250000</td>\n      <td>4.000000</td>\n      <td>0.471000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>26208.000000</td>\n      <td>4.000000</td>\n      <td>0.980000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"clean_train_2.describe()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T16:03:40.380566Z","iopub.execute_input":"2023-11-30T16:03:40.380834Z","iopub.status.idle":"2023-11-30T16:03:40.407057Z","shell.execute_reply.started":"2023-11-30T16:03:40.380803Z","shell.execute_reply":"2023-11-30T16:03:40.405863Z"},"trusted":true},"execution_count":108,"outputs":[{"execution_count":108,"output_type":"execute_result","data":{"text/plain":"                 id  median_relevance  relevance_variance\ncount   6206.000000       6206.000000         6206.000000\nmean   13154.066549          3.432646            0.202590\nstd     7570.559783          0.959901            0.232434\nmin        1.000000          1.000000            0.000000\n25%     6576.750000          3.000000            0.000000\n50%    13299.500000          4.000000            0.000000\n75%    19708.000000          4.000000            0.471000\nmax    26208.000000          4.000000            0.490000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>median_relevance</th>\n      <th>relevance_variance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>6206.000000</td>\n      <td>6206.000000</td>\n      <td>6206.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>13154.066549</td>\n      <td>3.432646</td>\n      <td>0.202590</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>7570.559783</td>\n      <td>0.959901</td>\n      <td>0.232434</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>6576.750000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>13299.500000</td>\n      <td>4.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>19708.000000</td>\n      <td>4.000000</td>\n      <td>0.471000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>26208.000000</td>\n      <td>4.000000</td>\n      <td>0.490000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"## Skipping product description as it's too lengthy and missing values\ntrain = clean_train_1\ntrain_input = train.apply(lambda x: x['query']+' '+x['product_title'], axis=1)\ndev_input =  dev.apply(lambda x: x['query']+' '+x['product_title'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T16:03:40.408652Z","iopub.execute_input":"2023-11-30T16:03:40.408919Z","iopub.status.idle":"2023-11-30T16:03:40.649959Z","shell.execute_reply.started":"2023-11-30T16:03:40.408888Z","shell.execute_reply":"2023-11-30T16:03:40.648988Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer \ntfidf = TfidfVectorizer(ngram_range=(1, 5),stop_words = 'english', strip_accents='unicode')\ntrain_x = tfidf.fit_transform(train_input)\ndev_x = tfidf.transform(dev_input)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T16:03:40.651630Z","iopub.execute_input":"2023-11-30T16:03:40.651891Z","iopub.status.idle":"2023-11-30T16:03:42.338102Z","shell.execute_reply.started":"2023-11-30T16:03:40.651860Z","shell.execute_reply":"2023-11-30T16:03:42.336689Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"train_y, dev_y = train.median_relevance.to_list(), dev.median_relevance.to_list()\ntrain_y = [(x-1)/3 for x in train_y]\ndev_y = [(x-1)/3 for x in dev_y]\nnp.mean(train_y), np.max(train_y), np.min(train_y)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T16:03:42.340279Z","iopub.execute_input":"2023-11-30T16:03:42.340620Z","iopub.status.idle":"2023-11-30T16:03:42.359533Z","shell.execute_reply.started":"2023-11-30T16:03:42.340584Z","shell.execute_reply":"2023-11-30T16:03:42.357929Z"},"trusted":true},"execution_count":111,"outputs":[{"execution_count":111,"output_type":"execute_result","data":{"text/plain":"(0.781467760430449, 1.0, 0.0)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, cohen_kappa_score, make_scorer\ndef reg_scorer(true, pred):\n    pred = [min(1, max(0,x)) for x in pred]\n    pred = [int(round((x*3)+1)) for x in pred]\n    true = [int(round((x*3)+1)) for x in true]\n    return cohen_kappa_score(true, pred)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T16:03:42.361351Z","iopub.execute_input":"2023-11-30T16:03:42.361757Z","iopub.status.idle":"2023-11-30T16:03:42.371550Z","shell.execute_reply.started":"2023-11-30T16:03:42.361705Z","shell.execute_reply":"2023-11-30T16:03:42.370054Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression, SGDRegressor\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVR\n#clf = LinearRegression().fit(train_x, train_y)\n#clf = SGDRegressor(verbose=1,n_iter_no_change=20).fit(train_x, train_y)\n'''param_grid = {'C': [1], 'epsilon':[0.1,0.05], 'kernel': ('linear', 'rbf')}\nsvr  = SVR()\nscorer = make_scorer(reg_scorer, greater_is_better=True)\nclf = GridSearchCV(svr, param_grid, verbose=True,scoring=scorer, n_jobs=8)\nclf.fit(train_x, train_y)\nclf.best_estimator_, clf.best_params_, clf.best_score_'''","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-11-30T16:03:42.373581Z","iopub.execute_input":"2023-11-30T16:03:42.373988Z","iopub.status.idle":"2023-11-30T16:03:42.386357Z","shell.execute_reply.started":"2023-11-30T16:03:42.373934Z","shell.execute_reply":"2023-11-30T16:03:42.385178Z"},"trusted":true},"execution_count":113,"outputs":[{"execution_count":113,"output_type":"execute_result","data":{"text/plain":"\"param_grid = {'C': [1], 'epsilon':[0.1,0.05], 'kernel': ('linear', 'rbf')}\\nsvr  = SVR()\\nscorer = make_scorer(reg_scorer, greater_is_better=True)\\nclf = GridSearchCV(svr, param_grid, verbose=True,scoring=scorer, n_jobs=8)\\nclf.fit(train_x, train_y)\\nclf.best_estimator_, clf.best_params_, clf.best_score_\""},"metadata":{}}]},{"cell_type":"code","source":"## 0.26 is the best score till now\n\n#preds = clf.best_estimator_.predict(dev_x)\n#mean_squared_error(dev_y, preds),  reg_scorer(dev_y, preds)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T16:03:42.388137Z","iopub.execute_input":"2023-11-30T16:03:42.388502Z","iopub.status.idle":"2023-11-30T16:03:42.398676Z","shell.execute_reply.started":"2023-11-30T16:03:42.388436Z","shell.execute_reply":"2023-11-30T16:03:42.397696Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"scorer = make_scorer(reg_scorer, greater_is_better=True)\n\n#GridSearch\n'''from sklearn.ensemble import StackingRegressor, RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.svm import SVR\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.metrics import make_scorer, mean_squared_error\nfrom sklearn.utils import check_random_state\n\nX_train, X_dev, y_train, y_dev = train_test_split(train_x, train_y, test_size=0.2, random_state=42)\n\n# Define base models\nsvr = SVR()\nrf = RandomForestRegressor()\ngb = GradientBoostingRegressor()\n\n\nmeta_model = LinearRegression()\n\n\n\n# Perform GridSearchCV for each base model\n'''\nparam_grid_svr = {'C': [0.1], 'epsilon': [0.01, 0.05], 'kernel': ['linear', 'rbf']}\nparam_grid_rf = {'n_estimators': [50, 200], 'max_depth': [None, 10]}\nparam_grid_gb = {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 0.2]}\n\n'''\n\nparam_grid_svr = {'C': [0.1], 'epsilon': [0.01, 0.05], 'kernel': ['linear', 'rbf']}\nparam_grid_rf = {'n_estimators': [50], 'max_depth': [10]}\nparam_grid_gb = {'n_estimators': [100], 'learning_rate': [0.05]}\n\ngrid_search_svr = GridSearchCV(svr, param_grid_svr, verbose=True, scoring=scorer, n_jobs=-1)\ngrid_search_rf = GridSearchCV(rf, param_grid_rf, verbose=True, scoring=scorer, n_jobs=-1)\ngrid_search_gb = GridSearchCV(gb, param_grid_gb, verbose=True, scoring=scorer, n_jobs=-1)\n\ngrid_search_svr.fit(X_train, y_train)\ngrid_search_rf.fit(X_train, y_train)\ngrid_search_gb.fit(X_train, y_train)\n\n# Get best estimators\nsvr_best_estimator = grid_search_svr.best_estimator_\nrf_best_estimator = grid_search_rf.best_estimator_\ngb_best_estimator = grid_search_gb.best_estimator_\n'''\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T16:03:42.400107Z","iopub.execute_input":"2023-11-30T16:03:42.400501Z","iopub.status.idle":"2023-11-30T16:03:42.418511Z","shell.execute_reply.started":"2023-11-30T16:03:42.400434Z","shell.execute_reply":"2023-11-30T16:03:42.416890Z"},"trusted":true},"execution_count":115,"outputs":[{"execution_count":115,"output_type":"execute_result","data":{"text/plain":"\"\\n\\nparam_grid_svr = {'C': [0.1], 'epsilon': [0.01, 0.05], 'kernel': ['linear', 'rbf']}\\nparam_grid_rf = {'n_estimators': [50], 'max_depth': [10]}\\nparam_grid_gb = {'n_estimators': [100], 'learning_rate': [0.05]}\\n\\ngrid_search_svr = GridSearchCV(svr, param_grid_svr, verbose=True, scoring=scorer, n_jobs=-1)\\ngrid_search_rf = GridSearchCV(rf, param_grid_rf, verbose=True, scoring=scorer, n_jobs=-1)\\ngrid_search_gb = GridSearchCV(gb, param_grid_gb, verbose=True, scoring=scorer, n_jobs=-1)\\n\\ngrid_search_svr.fit(X_train, y_train)\\ngrid_search_rf.fit(X_train, y_train)\\ngrid_search_gb.fit(X_train, y_train)\\n\\n# Get best estimators\\nsvr_best_estimator = grid_search_svr.best_estimator_\\nrf_best_estimator = grid_search_rf.best_estimator_\\ngb_best_estimator = grid_search_gb.best_estimator_\\n\""},"metadata":{}}]},{"cell_type":"code","source":"'''# Define stacking regressor with cross-validated predictions\nstacked_reg = StackingRegressor(\n    estimators=[('svr', svr), ('rf', rf), ('gb', gb)],\n    final_estimator=meta_model,\n    cv=5  \n)'''\n'''stacked_reg = StackingRegressor(\n    estimators=[('svr', grid_search_svr.best_estimator_),\n                ('rf', grid_search_rf.best_estimator_),\n                ('gb', grid_search_gb.best_estimator_)],\n    final_estimator=meta_model,\n    cv=5  # 5-fold cross-validation for stacking\n)\n# Fit the stacking regressor with the best base models\nstacked_reg.fit(X_train, y_train)\n\n# Evaluate on the validation set\ny_pred_stacked = stacked_reg.predict(X_dev)\nmse_stacked = mean_squared_error(y_dev, y_pred_stacked)\nprint(f'Mean Squared Error for Stacked Ensemble: {mse_stacked}')'''","metadata":{"execution":{"iopub.status.busy":"2023-11-30T16:03:42.420600Z","iopub.execute_input":"2023-11-30T16:03:42.421034Z","iopub.status.idle":"2023-11-30T16:03:42.436008Z","shell.execute_reply.started":"2023-11-30T16:03:42.420980Z","shell.execute_reply":"2023-11-30T16:03:42.434570Z"},"trusted":true},"execution_count":116,"outputs":[{"execution_count":116,"output_type":"execute_result","data":{"text/plain":"\"stacked_reg = StackingRegressor(\\n    estimators=[('svr', grid_search_svr.best_estimator_),\\n                ('rf', grid_search_rf.best_estimator_),\\n                ('gb', grid_search_gb.best_estimator_)],\\n    final_estimator=meta_model,\\n    cv=5  # 5-fold cross-validation for stacking\\n)\\n# Fit the stacking regressor with the best base models\\nstacked_reg.fit(X_train, y_train)\\n\\n# Evaluate on the validation set\\ny_pred_stacked = stacked_reg.predict(X_dev)\\nmse_stacked = mean_squared_error(y_dev, y_pred_stacked)\\nprint(f'Mean Squared Error for Stacked Ensemble: {mse_stacked}')\""},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import StackingRegressor, RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.linear_model import LinearRegression, Lasso\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.model_selection import RandomizedSearchCV, train_test_split\nfrom sklearn.metrics import make_scorer, mean_squared_error\nfrom scipy.stats import randint, uniform\n\n# Assuming you have train_x, train_y as your training data\nX_train, X_dev, y_train, y_dev = train_test_split(train_x, train_y, test_size=0.2, random_state=42)\n\n# Define base models\nsvr = SVR()\nrf = RandomForestRegressor()\ngb = GradientBoostingRegressor()\nknn = KNeighborsRegressor()\nlasso = Lasso()\n\n# Define meta-model\nmeta_model = LinearRegression()\n\n# Define parameter distributions for RandomizedSearchCV\n#param_dist_svr = {'C': uniform(0.1, 1.0), 'epsilon': uniform(0.01, 0.1), 'kernel': ['linear', 'rbf']}\nparam_grid_svr = {'C': [0.1], 'epsilon': [0.01, 0.05], 'kernel': ['linear', 'rbf']}\nparam_dist_rf = {'n_estimators': randint(50, 200), 'max_depth': [None, 10, 20]}\nparam_dist_gb = {'n_estimators': randint(50, 200), 'learning_rate': uniform(0.01, 0.2)}\nparam_dist_knn = {'n_neighbors': randint(1, 10), 'weights': ['uniform', 'distance']}\nparam_dist_lasso = {'alpha': uniform(0.1, 1.0)}\n\n# Perform RandomizedSearchCV for each base model\n#random_search_svr = RandomizedSearchCV(svr, param_distributions=param_dist_svr, n_iter=5, verbose=True, scoring=scorer, n_jobs=-1)\ngrid_search_svr = GridSearchCV(svr, param_grid_svr, verbose=True, scoring=scorer, n_jobs=-1)\nrandom_search_rf = RandomizedSearchCV(rf, param_distributions=param_dist_rf, n_iter=5, verbose=True, scoring=scorer, n_jobs=-1)\nrandom_search_gb = RandomizedSearchCV(gb, param_distributions=param_dist_gb, n_iter=5, verbose=True, scoring=scorer, n_jobs=-1)\nrandom_search_knn = RandomizedSearchCV(knn, param_distributions=param_dist_knn, n_iter=5, verbose=True, scoring=scorer, n_jobs=-1)\nrandom_search_lasso = RandomizedSearchCV(lasso, param_distributions=param_dist_lasso, n_iter=5, verbose=True, scoring=scorer, n_jobs=-1)\n\n#random_search_svr.fit(X_train, y_train)\ngrid_search_svr.fit(X_train, y_train)\nrandom_search_rf.fit(X_train, y_train)\nrandom_search_gb.fit(X_train, y_train)\nrandom_search_knn.fit(X_train, y_train)\nrandom_search_lasso.fit(X_train, y_train)\n\nweights = {'svr': 2.0, 'rf': 0.5, 'gb': 1.0, 'knn': 1.0, 'lasso': 1.0}\n\nstacked_reg = StackingRegressor(\n    estimators=[\n        ('svr', grid_search_svr.best_estimator_),\n        ('rf', random_search_rf.best_estimator_),\n        ('gb', random_search_gb.best_estimator_),\n        ('knn', random_search_knn.best_estimator_),\n        ('lasso', random_search_lasso.best_estimator_)\n    ],\n    final_estimator=meta_model,\n    cv = 5\n stack_method='predict',  # 'predict' means use the predictions as input to the final_estimator\n    n_jobs=-1,\n    passthrough=True,\n    weights=[weights[model_name] for model_name, _ in [('svr', svr), ('rf', rf), ('gb', gb), ('knn', knn), ('lasso', lasso)]]\n)\n\n# Fit the stacking regressor with the best base models\nstacked_reg.fit(X_train, y_train)\n\n# Evaluate on the validation set\ny_pred_stacked = stacked_reg.predict(X_dev)\nmse_stacked = mean_squared_error(y_dev, y_pred_stacked)\nprint(f'Mean Squared Error for Stacked Ensemble: {mse_stacked}')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T16:03:42.438149Z","iopub.execute_input":"2023-11-30T16:03:42.438528Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 10 candidates, totalling 50 fits\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.8min\n[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  2.1min finished\n","output_type":"stream"},{"name":"stdout","text":"Fitting 5 folds for each of 10 candidates, totalling 50 fits\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","output_type":"stream"}]},{"cell_type":"code","source":"test_input =  test.apply(lambda x: x['query']+' '+x['product_title'], axis=1)\ntest_x = tfidf.transform(test_input)\npred = stacked_reg.predict(test_x)\npred = [min(1, max(0,x)) for x in pred]\npred = [int(round((x*3)+1)) for x in pred]\nout = pd.DataFrame({\"id\": test.id.to_list(), \"prediction\": pred})\nout.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''test_input =  test.apply(lambda x: x['query']+' '+x['product_title'], axis=1)\ntest_x = tfidf.transform(test_input)\npred = clf.best_estimator_.predict(test_x)\npred = [min(1, max(0,x)) for x in pred]\npred = [int(round((x*3)+1)) for x in pred]\nout = pd.DataFrame({\"id\": test.id.to_list(), \"prediction\": pred})\nout.to_csv('submission.csv', index=False)'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv('/kaggle/input/crowdflower-search-relevance/sampleSubmission.csv.zip')\nsub\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}