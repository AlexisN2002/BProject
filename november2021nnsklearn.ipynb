{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport sklearn\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-17T20:22:57.582119Z","iopub.execute_input":"2023-10-17T20:22:57.586559Z","iopub.status.idle":"2023-10-17T20:22:57.635878Z","shell.execute_reply.started":"2023-10-17T20:22:57.586441Z","shell.execute_reply":"2023-10-17T20:22:57.633572Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"/kaggle/input/tabular-playground-series-nov-2021/sample_submission.csv\n/kaggle/input/tabular-playground-series-nov-2021/train.csv\n/kaggle/input/tabular-playground-series-nov-2021/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport wandb\nfrom wandb.keras import WandbCallback\nos.system('! wandb login be213aaff4ff14945d480abc18697d8664bba8c8')\ntraining = pd.read_csv('/kaggle/input/tabular-playground-series-nov-2021/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-nov-2021/test.csv')\ntest['target'] = np.NaN\ntraining['train_test'] = 1\ntest['train_test'] = 0\nall_data = pd.concat([training,test]) \n\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import OneHotEncoder\nattribute_names = all_data.columns.tolist()\ntest_atts = test.columns.tolist()\nall_dummies = pd.get_dummies(all_data[attribute_names])\ntest_dummies = pd.get_dummies(test[test_atts])  \nX_train = all_dummies[all_data.train_test == 1].drop(['train_test'], axis=1)\nfor column in X_train.columns:\n    mean_value = X_train[column].mean()\n    X_train[column].fillna(mean_value, inplace=True)\nX_check = X_train #for heatmap\nX_train = X_train.drop(['target'], axis=1)\nX_backup = X_train\nX_test = all_dummies[all_data.train_test == 0].drop(['train_test'], axis=1)\ny_train = all_data[all_data.train_test==1].target\ny_backup = y_train\nX_test = X_test.drop(['target'], axis=1)\nfor column in X_test.columns:\n    mean_value = X_test[column].mean()\n    X_test[column].fillna(mean_value, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-17T20:22:57.642680Z","iopub.execute_input":"2023-10-17T20:22:57.643090Z","iopub.status.idle":"2023-10-17T20:23:28.283355Z","shell.execute_reply.started":"2023-10-17T20:22:57.643056Z","shell.execute_reply":"2023-10-17T20:23:28.280572Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stderr","text":"wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\nwandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\nwandb: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[0;32mIn[49], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m os\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m! wandb login be213aaff4ff14945d480abc18697d8664bba8c8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m training \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/tabular-playground-series-nov-2021/train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/tabular-playground-series-nov-2021/test.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mNaN\n\u001b[1;32m      8\u001b[0m training[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_test\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1697\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1699\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1700\u001b[0m     (\n\u001b[1;32m   1701\u001b[0m         index,\n\u001b[1;32m   1702\u001b[0m         columns,\n\u001b[1;32m   1703\u001b[0m         col_dict,\n\u001b[0;32m-> 1704\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:814\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:875\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:850\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:861\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:2029\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n","\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."],"ename":"ParserError","evalue":"Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.","output_type":"error"}]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler, MinMaxScaler\nX_adapt = X_train.drop(['id'], axis=1)\nall_attributes =X_adapt.columns.tolist()\ncolumns_to_normalize = all_attributes\nscaler = MinMaxScaler()\nX_train_scaled = X_train\nX_train_scaled[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])\n#X_train_scaled = X_train_scaled[:,~np.all(np.isnan(d), axis=0)]\nX_test_scaled = X_test\nX_test_scaled[columns_to_normalize] = scaler.fit_transform(X_test[columns_to_normalize])\n\n#also norm. backup\nX_backup[columns_to_normalize] = scaler.fit_transform(X_backup[columns_to_normalize])","metadata":{"execution":{"iopub.status.busy":"2023-10-17T20:23:28.284322Z","iopub.status.idle":"2023-10-17T20:23:28.285202Z","shell.execute_reply.started":"2023-10-17T20:23:28.284689Z","shell.execute_reply":"2023-10-17T20:23:28.284769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_column = 'target'\n\n# Calculate the correlations between the target and all features\ncorrelations = training.corr()[target_column]\ncorrelations = correlations.drop('target')\n# Filter features with a correlation of at least 0.4 or -0.4\nsignificant_features = correlations[(correlations >= 0.05) | (correlations <= -0.05)]\nsignificant_features_index = correlations[(correlations >= 0.05) | (correlations <= -0.05)].index\n\n# Visualize the correlation values\nplt.figure(figsize=(10, 6))\nsns.barplot(x=significant_features.values, y=significant_features.index)\nplt.title(f'Features Correlating at least 0.1 or -0.1 with {target_column}')\nplt.xlabel('Correlation')\nplt.ylabel('Features')\nplt.show()\nX_train_sig = X_train_scaled[significant_features_index]\nX_test_sig = X_test_scaled[significant_features_index]\nprint(X_train_sig)","metadata":{"execution":{"iopub.status.busy":"2023-10-17T20:23:28.287566Z","iopub.status.idle":"2023-10-17T20:23:28.288109Z","shell.execute_reply.started":"2023-10-17T20:23:28.287877Z","shell.execute_reply":"2023-10-17T20:23:28.287905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nnum_samples = int(len(X_train_sig) * 0.2)\nrandom_indices = np.random.choice(len(X_train_sig), num_samples, replace=False)\nX_subset = X_train_sig.iloc[random_indices]\ny_subset = y_train.iloc[random_indices]\n#X_train = X_train_sig\nX_train, X_val, y_train, y_val = train_test_split(X_subset, y_subset, test_size=0.2, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2023-10-17T20:23:28.290534Z","iopub.status.idle":"2023-10-17T20:23:28.291133Z","shell.execute_reply.started":"2023-10-17T20:23:28.290831Z","shell.execute_reply":"2023-10-17T20:23:28.290857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train)","metadata":{"execution":{"iopub.status.busy":"2023-10-17T20:23:28.292799Z","iopub.status.idle":"2023-10-17T20:23:28.293377Z","shell.execute_reply.started":"2023-10-17T20:23:28.293082Z","shell.execute_reply":"2023-10-17T20:23:28.293110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import datetime\n\n# Get the current date and time\ncurrent_time = datetime.datetime.now()\n\n# Convert the current time to a string with a specific format\nformatted_time = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n\n# Create a string with the formatted time\ntime = f\"{formatted_time}\"","metadata":{"execution":{"iopub.status.busy":"2023-10-17T20:23:28.295508Z","iopub.status.idle":"2023-10-17T20:23:28.296370Z","shell.execute_reply.started":"2023-10-17T20:23:28.296126Z","shell.execute_reply":"2023-10-17T20:23:28.296148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install scikit-learn\n\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nimport wandb\n\n'''def create_neural_network():\n    model = MLPClassifier(\n        hidden_layer_sizes=(100,),\n        max_iter=200,\n        alpha=1e-4,\n        solver='adam',\n        activation='relu',\n        learning_rate_init=0.001,\n        random_state=1\n    )\n    return model\n\nwandb.init(project='KaggleNovemer2021NN', name='different NN'+time)\n\n# Define hyperparameters\nmodel = create_neural_network()\n\nmodel.fit(X_train, y_train)\n\n# Log the model's performance\nwandb.log({\"accuracy\": model.score(X_val, y_val)})\n\n# Finish the run\nwandb.finish()'''","metadata":{"execution":{"iopub.status.busy":"2023-10-17T20:23:28.297861Z","iopub.status.idle":"2023-10-17T20:23:28.298288Z","shell.execute_reply.started":"2023-10-17T20:23:28.298079Z","shell.execute_reply":"2023-10-17T20:23:28.298096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.init(project='KaggleNovemer2021NN', name='NN HPO '+time)\nparam_grid = {\n    'hidden_layer_sizes': [(100,), (150,), (200,)],\n    'max_iter': [300, 500],\n    'alpha': [1e-3, 1e-4, 1e-5],\n    'solver': ['adam'],\n    'activation': ['relu'],\n    'learning_rate_init': [0.001, 0.01, 0.05]\n}\n'''def create_neural_network():\n    model = MLPClassifier(\n        hidden_layer_sizes=(100,),\n        max_iter=200,\n        alpha=1e-4,\n        solver='adam',\n        activation='relu',\n        learning_rate_init=0.001,\n        random_state=1\n    )\n    return model'''\n\n# Create the neural network model\nmodel = MLPClassifier(random_state=1)\n\n# Perform hyperparameter tuning using GridSearchCV\ngrid_search = GridSearchCV(model, param_grid, cv=5, n_jobs=-1, scoring='accuracy')\ngrid_search.fit(X_train, y_train)\n\n# Log the best hyperparameters and corresponding accuracy\nbest_params = grid_search.best_params_\nbest_accuracy = grid_search.best_score_\nwandb.config.update(best_params)\nwandb.log({\"best_accuracy\": best_accuracy})\n\n# Fit the model with the best hyperparameters\nbest_model = MLPClassifier(**best_params, random_state=42)\nbest_model.fit(X_train, y_train)\n\n# Log the model's performance on the test set\ntest_accuracy = best_model.score(X_val, y_val)\nwandb.log({\"test_accuracy\": test_accuracy})\n\n# Finish the run\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2023-10-17T20:23:28.299619Z","iopub.status.idle":"2023-10-17T20:23:28.299976Z","shell.execute_reply.started":"2023-10-17T20:23:28.299810Z","shell.execute_reply":"2023-10-17T20:23:28.299826Z"},"trusted":true},"execution_count":null,"outputs":[]}]}