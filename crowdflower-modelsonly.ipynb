{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-01T12:42:23.965489Z","iopub.execute_input":"2023-12-01T12:42:23.965819Z","iopub.status.idle":"2023-12-01T12:42:23.974719Z","shell.execute_reply.started":"2023-12-01T12:42:23.965785Z","shell.execute_reply":"2023-12-01T12:42:23.973663Z"},"trusted":true},"execution_count":142,"outputs":[{"name":"stdout","text":"/kaggle/input/crowdflower-search-relevance/train.csv.zip\n/kaggle/input/crowdflower-search-relevance/sampleSubmission.csv.zip\n/kaggle/input/crowdflower-search-relevance/test.csv.zip\n","output_type":"stream"}]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/crowdflower-search-relevance/train.csv.zip')\ntest = pd.read_csv('/kaggle/input/crowdflower-search-relevance/test.csv.zip')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-01T12:42:23.979758Z","iopub.execute_input":"2023-12-01T12:42:23.980079Z","iopub.status.idle":"2023-12-01T12:42:24.442694Z","shell.execute_reply.started":"2023-12-01T12:42:23.980040Z","shell.execute_reply":"2023-12-01T12:42:24.441824Z"},"trusted":true},"execution_count":143,"outputs":[{"execution_count":143,"output_type":"execute_result","data":{"text/plain":"   id                      query  \\\n0   1  bridal shower decorations   \n1   2       led christmas lights   \n2   4                  projector   \n3   5                  wine rack   \n4   7                 light bulb   \n\n                                       product_title  \\\n0        Accent Pillow with Heart Design - Red/Black   \n1  Set of 10 Battery Operated Multi LED Train Chr...   \n2         ViewSonic Pro8200 DLP Multimedia Projector   \n3  Concept Housewares WR-44526 Solid-Wood Ceiling...   \n4  Wintergreen Lighting Christmas LED Light Bulb ...   \n\n                                 product_description  median_relevance  \\\n0  Red satin accent pillow embroidered with a hea...                 1   \n1  Set of 10 Battery Operated Train Christmas Lig...                 4   \n2                                                NaN                 4   \n3  Like a silent and sturdy tree, the Southern En...                 4   \n4  WTGR1011\\nFeatures\\nNickel base, 60,000 averag...                 2   \n\n   relevance_variance  \n0               0.000  \n1               0.000  \n2               0.471  \n3               0.000  \n4               0.471  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>query</th>\n      <th>product_title</th>\n      <th>product_description</th>\n      <th>median_relevance</th>\n      <th>relevance_variance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>bridal shower decorations</td>\n      <td>Accent Pillow with Heart Design - Red/Black</td>\n      <td>Red satin accent pillow embroidered with a hea...</td>\n      <td>1</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>led christmas lights</td>\n      <td>Set of 10 Battery Operated Multi LED Train Chr...</td>\n      <td>Set of 10 Battery Operated Train Christmas Lig...</td>\n      <td>4</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>projector</td>\n      <td>ViewSonic Pro8200 DLP Multimedia Projector</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>0.471</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>wine rack</td>\n      <td>Concept Housewares WR-44526 Solid-Wood Ceiling...</td>\n      <td>Like a silent and sturdy tree, the Southern En...</td>\n      <td>4</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>light bulb</td>\n      <td>Wintergreen Lighting Christmas LED Light Bulb ...</td>\n      <td>WTGR1011\\nFeatures\\nNickel base, 60,000 averag...</td>\n      <td>2</td>\n      <td>0.471</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2023-12-01T12:42:24.446520Z","iopub.execute_input":"2023-12-01T12:42:24.446868Z","iopub.status.idle":"2023-12-01T12:42:24.465013Z","shell.execute_reply.started":"2023-12-01T12:42:24.446834Z","shell.execute_reply":"2023-12-01T12:42:24.463946Z"},"trusted":true},"execution_count":144,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 10158 entries, 0 to 10157\nData columns (total 6 columns):\n #   Column               Non-Null Count  Dtype  \n---  ------               --------------  -----  \n 0   id                   10158 non-null  int64  \n 1   query                10158 non-null  object \n 2   product_title        10158 non-null  object \n 3   product_description  7714 non-null   object \n 4   median_relevance     10158 non-null  int64  \n 5   relevance_variance   10158 non-null  float64\ndtypes: float64(1), int64(2), object(3)\nmemory usage: 476.3+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"test.info()","metadata":{"execution":{"iopub.status.busy":"2023-12-01T12:42:24.466373Z","iopub.execute_input":"2023-12-01T12:42:24.466624Z","iopub.status.idle":"2023-12-01T12:42:24.488972Z","shell.execute_reply.started":"2023-12-01T12:42:24.466594Z","shell.execute_reply":"2023-12-01T12:42:24.487656Z"},"trusted":true},"execution_count":145,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 22513 entries, 0 to 22512\nData columns (total 4 columns):\n #   Column               Non-Null Count  Dtype \n---  ------               --------------  ----- \n 0   id                   22513 non-null  int64 \n 1   query                22513 non-null  object\n 2   product_title        22513 non-null  object\n 3   product_description  17086 non-null  object\ndtypes: int64(1), object(3)\nmemory usage: 703.7+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2023-12-01T12:42:24.491664Z","iopub.execute_input":"2023-12-01T12:42:24.492026Z","iopub.status.idle":"2023-12-01T12:42:24.516451Z","shell.execute_reply.started":"2023-12-01T12:42:24.491976Z","shell.execute_reply":"2023-12-01T12:42:24.515568Z"},"trusted":true},"execution_count":146,"outputs":[{"execution_count":146,"output_type":"execute_result","data":{"text/plain":"                 id  median_relevance  relevance_variance\ncount  10158.000000      10158.000000        10158.000000\nmean   16353.103071          3.309805            0.377863\nstd     9447.106683          0.980666            0.389707\nmin        1.000000          1.000000            0.000000\n25%     8078.750000          3.000000            0.000000\n50%    16349.500000          4.000000            0.471000\n75%    24570.750000          4.000000            0.471000\nmax    32668.000000          4.000000            1.470000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>median_relevance</th>\n      <th>relevance_variance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>10158.000000</td>\n      <td>10158.000000</td>\n      <td>10158.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>16353.103071</td>\n      <td>3.309805</td>\n      <td>0.377863</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>9447.106683</td>\n      <td>0.980666</td>\n      <td>0.389707</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>8078.750000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>16349.500000</td>\n      <td>4.000000</td>\n      <td>0.471000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>24570.750000</td>\n      <td>4.000000</td>\n      <td>0.471000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>32668.000000</td>\n      <td>4.000000</td>\n      <td>1.470000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train['query'].map(lambda x:len(x.split())).value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-12-01T12:42:24.517871Z","iopub.execute_input":"2023-12-01T12:42:24.518758Z","iopub.status.idle":"2023-12-01T12:42:24.536123Z","shell.execute_reply.started":"2023-12-01T12:42:24.518706Z","shell.execute_reply":"2023-12-01T12:42:24.534940Z"},"trusted":true},"execution_count":147,"outputs":[{"execution_count":147,"output_type":"execute_result","data":{"text/plain":"2    5379\n3    2819\n4     925\n1     885\n6      81\n5      69\nName: query, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"train['product_title'].map(lambda x:len(x.split())).value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-12-01T12:42:24.537477Z","iopub.execute_input":"2023-12-01T12:42:24.538132Z","iopub.status.idle":"2023-12-01T12:42:24.563884Z","shell.execute_reply.started":"2023-12-01T12:42:24.538075Z","shell.execute_reply":"2023-12-01T12:42:24.563139Z"},"trusted":true},"execution_count":148,"outputs":[{"execution_count":148,"output_type":"execute_result","data":{"text/plain":"7     1288\n6     1284\n8     1183\n9     1122\n5     1002\n10     880\n11     744\n12     678\n4      550\n13     453\n14     289\n15     181\n3      174\n17      78\n16      66\n2       51\n18      25\n19      24\n20      15\n24      11\n21       7\n25       7\n27       6\n26       6\n22       6\n28       6\n23       6\n29       4\n1        2\n46       2\n32       2\n38       1\n44       1\n34       1\n31       1\n43       1\n41       1\nName: product_title, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"split = int(len(train)*0.8)\ntrain_0, dev = train[:split], train[split:]","metadata":{"execution":{"iopub.status.busy":"2023-12-01T12:42:24.564945Z","iopub.execute_input":"2023-12-01T12:42:24.565678Z","iopub.status.idle":"2023-12-01T12:42:24.576764Z","shell.execute_reply.started":"2023-12-01T12:42:24.565634Z","shell.execute_reply":"2023-12-01T12:42:24.574755Z"},"trusted":true},"execution_count":149,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clean_train_1 = train_0[train_0.relevance_variance <1].copy()\nclean_train_2 = train_0[train_0.relevance_variance <0.50].copy()\ndev.describe()","metadata":{"execution":{"iopub.status.busy":"2023-12-01T12:42:24.577982Z","iopub.execute_input":"2023-12-01T12:42:24.578300Z","iopub.status.idle":"2023-12-01T12:42:24.611774Z","shell.execute_reply.started":"2023-12-01T12:42:24.578251Z","shell.execute_reply":"2023-12-01T12:42:24.610851Z"},"trusted":true},"execution_count":150,"outputs":[{"execution_count":150,"output_type":"execute_result","data":{"text/plain":"                 id  median_relevance  relevance_variance\ncount   2032.000000       2032.000000         2032.000000\nmean   29406.014764          3.319390            0.361364\nstd     1870.217123          0.972218            0.379619\nmin    26215.000000          1.000000            0.000000\n25%    27777.250000          3.000000            0.000000\n50%    29410.000000          4.000000            0.471000\n75%    31014.750000          4.000000            0.471000\nmax    32668.000000          4.000000            1.470000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>median_relevance</th>\n      <th>relevance_variance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2032.000000</td>\n      <td>2032.000000</td>\n      <td>2032.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>29406.014764</td>\n      <td>3.319390</td>\n      <td>0.361364</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1870.217123</td>\n      <td>0.972218</td>\n      <td>0.379619</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>26215.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>27777.250000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>29410.000000</td>\n      <td>4.000000</td>\n      <td>0.471000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>31014.750000</td>\n      <td>4.000000</td>\n      <td>0.471000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>32668.000000</td>\n      <td>4.000000</td>\n      <td>1.470000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"clean_train_1.describe()","metadata":{"execution":{"iopub.status.busy":"2023-12-01T12:42:24.612925Z","iopub.execute_input":"2023-12-01T12:42:24.613163Z","iopub.status.idle":"2023-12-01T12:42:24.636099Z","shell.execute_reply.started":"2023-12-01T12:42:24.613135Z","shell.execute_reply":"2023-12-01T12:42:24.635472Z"},"trusted":true},"execution_count":151,"outputs":[{"execution_count":151,"output_type":"execute_result","data":{"text/plain":"                 id  median_relevance  relevance_variance\ncount   7558.000000       7558.000000         7558.000000\nmean   13074.201111          3.344403            0.321038\nstd     7571.543134          0.974908            0.332482\nmin        1.000000          1.000000            0.000000\n25%     6496.500000          3.000000            0.000000\n50%    13129.000000          4.000000            0.471000\n75%    19563.250000          4.000000            0.471000\nmax    26208.000000          4.000000            0.980000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>median_relevance</th>\n      <th>relevance_variance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>7558.000000</td>\n      <td>7558.000000</td>\n      <td>7558.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>13074.201111</td>\n      <td>3.344403</td>\n      <td>0.321038</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>7571.543134</td>\n      <td>0.974908</td>\n      <td>0.332482</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>6496.500000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>13129.000000</td>\n      <td>4.000000</td>\n      <td>0.471000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>19563.250000</td>\n      <td>4.000000</td>\n      <td>0.471000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>26208.000000</td>\n      <td>4.000000</td>\n      <td>0.980000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"clean_train_2.describe()","metadata":{"execution":{"iopub.status.busy":"2023-12-01T12:42:24.638566Z","iopub.execute_input":"2023-12-01T12:42:24.639222Z","iopub.status.idle":"2023-12-01T12:42:24.661314Z","shell.execute_reply.started":"2023-12-01T12:42:24.639184Z","shell.execute_reply":"2023-12-01T12:42:24.660451Z"},"trusted":true},"execution_count":152,"outputs":[{"execution_count":152,"output_type":"execute_result","data":{"text/plain":"                 id  median_relevance  relevance_variance\ncount   6206.000000       6206.000000         6206.000000\nmean   13154.066549          3.432646            0.202590\nstd     7570.559783          0.959901            0.232434\nmin        1.000000          1.000000            0.000000\n25%     6576.750000          3.000000            0.000000\n50%    13299.500000          4.000000            0.000000\n75%    19708.000000          4.000000            0.471000\nmax    26208.000000          4.000000            0.490000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>median_relevance</th>\n      <th>relevance_variance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>6206.000000</td>\n      <td>6206.000000</td>\n      <td>6206.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>13154.066549</td>\n      <td>3.432646</td>\n      <td>0.202590</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>7570.559783</td>\n      <td>0.959901</td>\n      <td>0.232434</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>6576.750000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>13299.500000</td>\n      <td>4.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>19708.000000</td>\n      <td>4.000000</td>\n      <td>0.471000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>26208.000000</td>\n      <td>4.000000</td>\n      <td>0.490000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"## Skipping product description as it's too lengthy and missing values\ntrain = clean_train_1\ntrain_input = train.apply(lambda x: x['query']+' '+x['product_title'], axis=1)\ndev_input =  dev.apply(lambda x: x['query']+' '+x['product_title'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T12:42:24.662429Z","iopub.execute_input":"2023-12-01T12:42:24.662662Z","iopub.status.idle":"2023-12-01T12:42:24.824764Z","shell.execute_reply.started":"2023-12-01T12:42:24.662633Z","shell.execute_reply":"2023-12-01T12:42:24.824067Z"},"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer \ntfidf = TfidfVectorizer(ngram_range=(1, 5),stop_words = 'english', strip_accents='unicode')\ntrain_x = tfidf.fit_transform(train_input)\ndev_x = tfidf.transform(dev_input)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T12:42:24.826021Z","iopub.execute_input":"2023-12-01T12:42:24.826451Z","iopub.status.idle":"2023-12-01T12:42:25.963359Z","shell.execute_reply.started":"2023-12-01T12:42:24.826415Z","shell.execute_reply":"2023-12-01T12:42:25.962427Z"},"trusted":true},"execution_count":154,"outputs":[]},{"cell_type":"code","source":"train_y, dev_y = train.median_relevance.to_list(), dev.median_relevance.to_list()\ntrain_y = [(x-1)/3 for x in train_y]\ndev_y = [(x-1)/3 for x in dev_y]\nnp.mean(train_y), np.max(train_y), np.min(train_y)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T12:42:25.964753Z","iopub.execute_input":"2023-12-01T12:42:25.965271Z","iopub.status.idle":"2023-12-01T12:42:25.980770Z","shell.execute_reply.started":"2023-12-01T12:42:25.965225Z","shell.execute_reply":"2023-12-01T12:42:25.979713Z"},"trusted":true},"execution_count":155,"outputs":[{"execution_count":155,"output_type":"execute_result","data":{"text/plain":"(0.781467760430449, 1.0, 0.0)"},"metadata":{}}]},{"cell_type":"code","source":"import datetime\ncurrent_time = datetime.datetime.now()\nformatted_time = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\ntime = f\"{formatted_time}\"","metadata":{"execution":{"iopub.status.busy":"2023-12-01T12:42:25.982077Z","iopub.execute_input":"2023-12-01T12:42:25.982786Z","iopub.status.idle":"2023-12-01T12:42:25.987184Z","shell.execute_reply.started":"2023-12-01T12:42:25.982736Z","shell.execute_reply":"2023-12-01T12:42:25.986574Z"},"trusted":true},"execution_count":156,"outputs":[]},{"cell_type":"code","source":"import os\nimport wandb\nfrom wandb.keras import WandbCallback\nos.system('! wandb login be213aaff4ff14945d480abc18697d8664bba8c8')","metadata":{"execution":{"iopub.status.busy":"2023-12-01T12:42:25.988360Z","iopub.execute_input":"2023-12-01T12:42:25.988630Z","iopub.status.idle":"2023-12-01T12:42:28.032246Z","shell.execute_reply.started":"2023-12-01T12:42:25.988598Z","shell.execute_reply":"2023-12-01T12:42:28.031253Z"},"trusted":true},"execution_count":157,"outputs":[{"name":"stderr","text":"wandb: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":157,"output_type":"execute_result","data":{"text/plain":"256"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, cohen_kappa_score, make_scorer\ndef reg_scorer(true, pred):\n    pred = [min(1, max(0,x)) for x in pred]\n    pred = [int(round((x*3)+1)) for x in pred]\n    true = [int(round((x*3)+1)) for x in true]\n    return cohen_kappa_score(true, pred)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T12:42:28.034913Z","iopub.execute_input":"2023-12-01T12:42:28.035251Z","iopub.status.idle":"2023-12-01T12:42:28.043250Z","shell.execute_reply.started":"2023-12-01T12:42:28.035207Z","shell.execute_reply":"2023-12-01T12:42:28.041668Z"},"trusted":true},"execution_count":158,"outputs":[]},{"cell_type":"code","source":"wandb.init(project='CrowdflowerModelsOnly', name='figuring out params '+time)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T12:42:28.045218Z","iopub.execute_input":"2023-12-01T12:42:28.045629Z","iopub.status.idle":"2023-12-01T12:42:39.928256Z","shell.execute_reply.started":"2023-12-01T12:42:28.045589Z","shell.execute_reply":"2023-12-01T12:42:39.927431Z"},"trusted":true},"execution_count":159,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:3jxhvqgf) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 316... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n</div><div class=\"wandb-col\">\n</div></div>\nSynced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">figuring out params 2023-12-01 12:41:39</strong>: <a href=\"https://wandb.ai/bachelorproject/CrowdflowerModelsOnly/runs/3jxhvqgf\" target=\"_blank\">https://wandb.ai/bachelorproject/CrowdflowerModelsOnly/runs/3jxhvqgf</a><br/>\nFind logs at: <code>./wandb/run-20231201_124142-3jxhvqgf/logs</code><br/>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:3jxhvqgf). Initializing new run:<br/>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.0 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    Syncing run <strong><a href=\"https://wandb.ai/bachelorproject/CrowdflowerModelsOnly/runs/25n9i32b\" target=\"_blank\">figuring out params 2023-12-01 12:42:25</a></strong> to <a href=\"https://wandb.ai/bachelorproject/CrowdflowerModelsOnly\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "},"metadata":{}},{"execution_count":159,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/bachelorproject/CrowdflowerModelsOnly/runs/25n9i32b?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7ca110825e10>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression, SGDRegressor\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVR\n#clf = LinearRegression().fit(train_x, train_y)\n#clf = SGDRegressor(verbose=1,n_iter_no_change=20).fit(train_x, train_y)\n'''param_grid = {'C': [1], 'epsilon':[0.1,0.05], 'kernel': ('linear', 'rbf')}\nsvr  = SVR()\nscorer = make_scorer(reg_scorer, greater_is_better=True)\nclf = GridSearchCV(svr, param_grid, verbose=True,scoring=scorer, n_jobs=8)\nclf.fit(train_x, train_y)\nclf.best_estimator_, clf.best_params_, clf.best_score_'''","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-12-01T12:42:39.930095Z","iopub.execute_input":"2023-12-01T12:42:39.931096Z","iopub.status.idle":"2023-12-01T12:42:39.939525Z","shell.execute_reply.started":"2023-12-01T12:42:39.931045Z","shell.execute_reply":"2023-12-01T12:42:39.938621Z"},"trusted":true},"execution_count":160,"outputs":[{"execution_count":160,"output_type":"execute_result","data":{"text/plain":"\"param_grid = {'C': [1], 'epsilon':[0.1,0.05], 'kernel': ('linear', 'rbf')}\\nsvr  = SVR()\\nscorer = make_scorer(reg_scorer, greater_is_better=True)\\nclf = GridSearchCV(svr, param_grid, verbose=True,scoring=scorer, n_jobs=8)\\nclf.fit(train_x, train_y)\\nclf.best_estimator_, clf.best_params_, clf.best_score_\""},"metadata":{}}]},{"cell_type":"code","source":"## 0.26 is the best score till now\n\n#preds = clf.best_estimator_.predict(dev_x)\n#mean_squared_error(dev_y, preds),  reg_scorer(dev_y, preds)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T12:42:39.941686Z","iopub.execute_input":"2023-12-01T12:42:39.942328Z","iopub.status.idle":"2023-12-01T12:42:39.952674Z","shell.execute_reply.started":"2023-12-01T12:42:39.942282Z","shell.execute_reply":"2023-12-01T12:42:39.951576Z"},"trusted":true},"execution_count":161,"outputs":[]},{"cell_type":"code","source":"scorer = make_scorer(reg_scorer, greater_is_better=True)\n\n#GridSearch\n'''from sklearn.ensemble import StackingRegressor, RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.svm import SVR\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.metrics import make_scorer, mean_squared_error\nfrom sklearn.utils import check_random_state\n\nX_train, X_dev, y_train, y_dev = train_test_split(train_x, train_y, test_size=0.2, random_state=42)\n\n# Define base models\nsvr = SVR()\nrf = RandomForestRegressor()\ngb = GradientBoostingRegressor()\n\n\nmeta_model = LinearRegression()\n\n\n\n# Perform GridSearchCV for each base model\n'''\nparam_grid_svr = {'C': [0.1], 'epsilon': [0.01, 0.05], 'kernel': ['linear', 'rbf']}\nparam_grid_rf = {'n_estimators': [50, 200], 'max_depth': [None, 10]}\nparam_grid_gb = {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 0.2]}\n\n'''\n\nparam_grid_svr = {'C': [0.1], 'epsilon': [0.01, 0.05], 'kernel': ['linear', 'rbf']}\nparam_grid_rf = {'n_estimators': [50], 'max_depth': [10]}\nparam_grid_gb = {'n_estimators': [100], 'learning_rate': [0.05]}\n\ngrid_search_svr = GridSearchCV(svr, param_grid_svr, verbose=True, scoring=scorer, n_jobs=-1)\ngrid_search_rf = GridSearchCV(rf, param_grid_rf, verbose=True, scoring=scorer, n_jobs=-1)\ngrid_search_gb = GridSearchCV(gb, param_grid_gb, verbose=True, scoring=scorer, n_jobs=-1)\n\ngrid_search_svr.fit(X_train, y_train)\ngrid_search_rf.fit(X_train, y_train)\ngrid_search_gb.fit(X_train, y_train)\n\n# Get best estimators\nsvr_best_estimator = grid_search_svr.best_estimator_\nrf_best_estimator = grid_search_rf.best_estimator_\ngb_best_estimator = grid_search_gb.best_estimator_\n'''\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-01T12:42:39.954252Z","iopub.execute_input":"2023-12-01T12:42:39.959803Z","iopub.status.idle":"2023-12-01T12:42:39.974787Z","shell.execute_reply.started":"2023-12-01T12:42:39.959727Z","shell.execute_reply":"2023-12-01T12:42:39.973637Z"},"trusted":true},"execution_count":162,"outputs":[{"execution_count":162,"output_type":"execute_result","data":{"text/plain":"\"\\n\\nparam_grid_svr = {'C': [0.1], 'epsilon': [0.01, 0.05], 'kernel': ['linear', 'rbf']}\\nparam_grid_rf = {'n_estimators': [50], 'max_depth': [10]}\\nparam_grid_gb = {'n_estimators': [100], 'learning_rate': [0.05]}\\n\\ngrid_search_svr = GridSearchCV(svr, param_grid_svr, verbose=True, scoring=scorer, n_jobs=-1)\\ngrid_search_rf = GridSearchCV(rf, param_grid_rf, verbose=True, scoring=scorer, n_jobs=-1)\\ngrid_search_gb = GridSearchCV(gb, param_grid_gb, verbose=True, scoring=scorer, n_jobs=-1)\\n\\ngrid_search_svr.fit(X_train, y_train)\\ngrid_search_rf.fit(X_train, y_train)\\ngrid_search_gb.fit(X_train, y_train)\\n\\n# Get best estimators\\nsvr_best_estimator = grid_search_svr.best_estimator_\\nrf_best_estimator = grid_search_rf.best_estimator_\\ngb_best_estimator = grid_search_gb.best_estimator_\\n\""},"metadata":{}}]},{"cell_type":"code","source":"'''# Define stacking regressor with cross-validated predictions\nstacked_reg = StackingRegressor(\n    estimators=[('svr', svr), ('rf', rf), ('gb', gb)],\n    final_estimator=meta_model,\n    cv=5  \n)'''\n'''stacked_reg = StackingRegressor(\n    estimators=[('svr', grid_search_svr.best_estimator_),\n                ('rf', grid_search_rf.best_estimator_),\n                ('gb', grid_search_gb.best_estimator_)],\n    final_estimator=meta_model,\n    cv=5  # 5-fold cross-validation for stacking\n)\n# Fit the stacking regressor with the best base models\nstacked_reg.fit(X_train, y_train)\n\n# Evaluate on the validation set\ny_pred_stacked = stacked_reg.predict(X_dev)\nmse_stacked = mean_squared_error(y_dev, y_pred_stacked)\nprint(f'Mean Squared Error for Stacked Ensemble: {mse_stacked}')'''","metadata":{"execution":{"iopub.status.busy":"2023-12-01T12:42:39.976955Z","iopub.execute_input":"2023-12-01T12:42:39.977310Z","iopub.status.idle":"2023-12-01T12:42:39.991922Z","shell.execute_reply.started":"2023-12-01T12:42:39.977261Z","shell.execute_reply":"2023-12-01T12:42:39.990692Z"},"trusted":true},"execution_count":163,"outputs":[{"execution_count":163,"output_type":"execute_result","data":{"text/plain":"\"stacked_reg = StackingRegressor(\\n    estimators=[('svr', grid_search_svr.best_estimator_),\\n                ('rf', grid_search_rf.best_estimator_),\\n                ('gb', grid_search_gb.best_estimator_)],\\n    final_estimator=meta_model,\\n    cv=5  # 5-fold cross-validation for stacking\\n)\\n# Fit the stacking regressor with the best base models\\nstacked_reg.fit(X_train, y_train)\\n\\n# Evaluate on the validation set\\ny_pred_stacked = stacked_reg.predict(X_dev)\\nmse_stacked = mean_squared_error(y_dev, y_pred_stacked)\\nprint(f'Mean Squared Error for Stacked Ensemble: {mse_stacked}')\""},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import StackingRegressor, RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.linear_model import LinearRegression, Lasso\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.model_selection import RandomizedSearchCV, train_test_split\nfrom sklearn.metrics import make_scorer, mean_squared_error\nfrom scipy.stats import randint, uniform\n\n# Assuming you have train_x, train_y as your training data\nX_train, X_dev, y_train, y_dev = train_test_split(train_x, train_y, test_size=0.2, random_state=42)\n\n# Define base models\nsvr = SVR()\nrf = RandomForestRegressor()\ngb = GradientBoostingRegressor()\nknn = KNeighborsRegressor()\nlasso = Lasso()\n\n# Define meta-model\nmeta_model = LinearRegression()\n\n# Define parameter distributions for RandomizedSearchCV\n#param_dist_svr = {'C': uniform(0.1, 1.0), 'epsilon': uniform(0.01, 0.1), 'kernel': ['linear', 'rbf']}\n#param_grid_svr = {'C': [0.1], 'epsilon': [0.01, 0.05], 'kernel': ['linear', 'rbf']}\n\n#updated grid\nparam_grid = {\n    'estimator__C': [0.001, 0.01, 0.1],\n    'estimator__kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n    'estimator__gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1, 10],\n    'estimator__epsilon': [0.01, 0.05],\n    'estimator__degree': [2, 3, 4, 5],\n    'estimator__coef0': [0.0, 0.1, 0.5, 1.0],\n    'estimator__shrinking': [True, False],\n    'estimator__max_iter': [-1, 100, 500, 1000],\n}\n\nparam_dist_rf = {'n_estimators': randint(50, 200), 'max_depth': [None, 10, 20]}\nparam_dist_gb = {'n_estimators': randint(50, 200), 'learning_rate': uniform(0.01, 0.2)}\nparam_dist_knn = {'n_neighbors': randint(1, 10), 'weights': ['uniform', 'distance']}\nparam_dist_lasso = {'alpha': uniform(0.1, 1.0)}\n\n# Perform RandomizedSearchCV for each base model\n#random_search_svr = RandomizedSearchCV(svr, param_distributions=param_dist_svr, n_iter=5, verbose=True, scoring=scorer, n_jobs=-1)\ngrid_search_svr = GridSearchCV(svr, param_grid_svr, verbose=True, scoring=scorer, cv=5, n_jobs=-1)\n###\n\ngrid_search_svr.fit(X_train, y_train)\n\ny_pred_svr = grid_search_svr.predict(X_dev)\nmse_svr = mean_squared_error(y_dev, y_pred_svr)\n#wandb.log(grid_search_svr.get_params())\n#wandb.sklearn.log_model(grid_search_svr)\nsvr_params = grid_search_svr.get_params()\nmodels = {\n    \"SVR\": {\n        \"model\": grid_search_svr,\n        \"params\": svr_params,\n        \"score\" : mse_svr,\n        \"best estimator\": grid_search_svr.best_estimator_\n    },\n    \"SVR\": {\n        \"model\": grid_search_svr,\n        \"params\": svr_params,\n        \"score\" : mse_svr\n    }\n}\nwandb.config.update(models)\n\nwandb.finish()\n\ntest_input =  test.apply(lambda x: x['query']+' '+x['product_title'], axis=1)\ntest_x = tfidf.transform(test_input)\npred = grid_search_svr.best_estimator_.predict(test_x)\npred = [min(1, max(0,x)) for x in pred]\npred = [int(round((x*3)+1)) for x in pred]\nout = pd.DataFrame({\"id\": test.id.to_list(), \"prediction\": pred})\nout.to_csv('submission.csv', index=False)\n\n####\n\nrandom_search_rf = RandomizedSearchCV(rf, param_distributions=param_dist_rf, n_iter=5, verbose=True, scoring=scorer, n_jobs=-1)\nrandom_search_gb = RandomizedSearchCV(gb, param_distributions=param_dist_gb, n_iter=5, verbose=True, scoring=scorer, n_jobs=-1)\nrandom_search_knn = RandomizedSearchCV(knn, param_distributions=param_dist_knn, n_iter=5, verbose=True, scoring=scorer, n_jobs=-1)\nrandom_search_lasso = RandomizedSearchCV(lasso, param_distributions=param_dist_lasso, n_iter=5, verbose=True, scoring=scorer, n_jobs=-1)\n\n#random_search_svr.fit(X_train, y_train)\ngrid_search_svr.fit(X_train, y_train)\nrandom_search_rf.fit(X_train, y_train)\nrandom_search_gb.fit(X_train, y_train)\nrandom_search_knn.fit(X_train, y_train)\nrandom_search_lasso.fit(X_train, y_train)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-01T12:42:39.994047Z","iopub.execute_input":"2023-12-01T12:42:39.994625Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 4 candidates, totalling 20 fits\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n\nCondaEnvException: Unable to determine environment\n\nPlease re-run this command with one of the following options:\n\n* Provide an environment name via --name or -n\n* Re-run this command inside an activated conda environment.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred_svr = grid_search_svr.predict(X_dev)\nmse_svr = mean_squared_error(y_dev, y_pred_svr)\n#wandb.log(grid_search_svr.get_params())\n#wandb.sklearn.log_model(grid_search_svr)\nsvr_params = grid_search_svr.get_params()\nmodels = {\n    \"SVR\": {\n        \"model\": grid_search_svr,\n        \"params\": svr_params,\n        \"score\" : mse_svr\n    },\n    \"SVR\": {\n        \"model\": grid_search_svr,\n        \"params\": svr_params,\n        \"score\" : mse_svr\n    }\n}\nwandb.config.update(models)\n#wandb.log(mse_svr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weights = {'svr': 2.0, 'rf': 0.5, 'gb': 1.0, 'knn': 1.0, 'lasso': 1.0}\n#apparently we cant use weights here\n\nstacked_reg = StackingRegressor(\n    estimators=[\n        ('svr', grid_search_svr.best_estimator_),\n        #('rf', random_search_rf.best_estimator_),\n        ('gb', random_search_gb.best_estimator_),\n        ('knn', random_search_knn.best_estimator_),\n        ('lasso', random_search_lasso.best_estimator_)\n    ],\n    final_estimator=meta_model,\n    cv = 5,\n    n_jobs=-1,\n    passthrough=True,\n    #weights=[weights[model_name] for model_name, _ in [('svr', svr), ('rf', rf), ('gb', gb), ('knn', knn), ('lasso', lasso)]]\n)\n\n# Fit the stacking regressor with the best base models\nstacked_reg.fit(X_train, y_train)\n\n# Evaluate on the validation set\ny_pred_stacked = stacked_reg.predict(X_dev)\nmse_stacked = mean_squared_error(y_dev, y_pred_stacked)\nprint(f'Mean Squared Error for Stacked Ensemble: {mse_stacked}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_input =  test.apply(lambda x: x['query']+' '+x['product_title'], axis=1)\ntest_x = tfidf.transform(test_input)\npred = stacked_reg.predict(test_x)\npred = [min(1, max(0,x)) for x in pred]\npred = [int(round((x*3)+1)) for x in pred]\nout = pd.DataFrame({\"id\": test.id.to_list(), \"prediction\": pred})\nout.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''test_input =  test.apply(lambda x: x['query']+' '+x['product_title'], axis=1)\ntest_x = tfidf.transform(test_input)\npred = clf.best_estimator_.predict(test_x)\npred = [min(1, max(0,x)) for x in pred]\npred = [int(round((x*3)+1)) for x in pred]\nout = pd.DataFrame({\"id\": test.id.to_list(), \"prediction\": pred})\nout.to_csv('submission.csv', index=False)'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv('/kaggle/input/crowdflower-search-relevance/sampleSubmission.csv.zip')\nsub\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.finish()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}