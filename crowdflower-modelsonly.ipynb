{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4407,"databundleVersionId":34172,"sourceType":"competition"}],"dockerImageVersionId":30138,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-01T13:54:06.927201Z","iopub.execute_input":"2023-12-01T13:54:06.927983Z","iopub.status.idle":"2023-12-01T13:54:06.938598Z","shell.execute_reply.started":"2023-12-01T13:54:06.927923Z","shell.execute_reply":"2023-12-01T13:54:06.937653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/crowdflower-search-relevance/train.csv.zip')\ntest = pd.read_csv('/kaggle/input/crowdflower-search-relevance/test.csv.zip')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-01T13:54:06.944716Z","iopub.execute_input":"2023-12-01T13:54:06.945027Z","iopub.status.idle":"2023-12-01T13:54:07.390712Z","shell.execute_reply.started":"2023-12-01T13:54:06.944992Z","shell.execute_reply":"2023-12-01T13:54:07.389888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2023-12-01T13:54:07.392462Z","iopub.execute_input":"2023-12-01T13:54:07.392690Z","iopub.status.idle":"2023-12-01T13:54:07.409839Z","shell.execute_reply.started":"2023-12-01T13:54:07.392663Z","shell.execute_reply":"2023-12-01T13:54:07.408732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info()","metadata":{"execution":{"iopub.status.busy":"2023-12-01T13:54:07.411473Z","iopub.execute_input":"2023-12-01T13:54:07.411746Z","iopub.status.idle":"2023-12-01T13:54:07.431240Z","shell.execute_reply.started":"2023-12-01T13:54:07.411711Z","shell.execute_reply":"2023-12-01T13:54:07.430142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2023-12-01T13:54:07.433191Z","iopub.execute_input":"2023-12-01T13:54:07.433444Z","iopub.status.idle":"2023-12-01T13:54:07.455237Z","shell.execute_reply.started":"2023-12-01T13:54:07.433385Z","shell.execute_reply":"2023-12-01T13:54:07.454278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['query'].map(lambda x:len(x.split())).value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-12-01T13:54:07.456340Z","iopub.execute_input":"2023-12-01T13:54:07.456598Z","iopub.status.idle":"2023-12-01T13:54:07.470919Z","shell.execute_reply.started":"2023-12-01T13:54:07.456567Z","shell.execute_reply":"2023-12-01T13:54:07.470172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['product_title'].map(lambda x:len(x.split())).value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-12-01T13:54:07.471910Z","iopub.execute_input":"2023-12-01T13:54:07.472146Z","iopub.status.idle":"2023-12-01T13:54:07.497324Z","shell.execute_reply.started":"2023-12-01T13:54:07.472115Z","shell.execute_reply":"2023-12-01T13:54:07.496425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"split = int(len(train)*0.8)\ntrain_0, dev = train[:split], train[split:]","metadata":{"execution":{"iopub.status.busy":"2023-12-01T13:54:07.498836Z","iopub.execute_input":"2023-12-01T13:54:07.499141Z","iopub.status.idle":"2023-12-01T13:54:07.504515Z","shell.execute_reply.started":"2023-12-01T13:54:07.499099Z","shell.execute_reply":"2023-12-01T13:54:07.503599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clean_train_1 = train_0[train_0.relevance_variance <1].copy()\nclean_train_2 = train_0[train_0.relevance_variance <0.50].copy()\ndev.describe()","metadata":{"execution":{"iopub.status.busy":"2023-12-01T13:54:07.506160Z","iopub.execute_input":"2023-12-01T13:54:07.506632Z","iopub.status.idle":"2023-12-01T13:54:07.539548Z","shell.execute_reply.started":"2023-12-01T13:54:07.506583Z","shell.execute_reply":"2023-12-01T13:54:07.538455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clean_train_1.describe()","metadata":{"execution":{"iopub.status.busy":"2023-12-01T13:54:07.540918Z","iopub.execute_input":"2023-12-01T13:54:07.541147Z","iopub.status.idle":"2023-12-01T13:54:07.566066Z","shell.execute_reply.started":"2023-12-01T13:54:07.541118Z","shell.execute_reply":"2023-12-01T13:54:07.564993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clean_train_2.describe()","metadata":{"execution":{"iopub.status.busy":"2023-12-01T13:54:07.568851Z","iopub.execute_input":"2023-12-01T13:54:07.569107Z","iopub.status.idle":"2023-12-01T13:54:07.592552Z","shell.execute_reply.started":"2023-12-01T13:54:07.569077Z","shell.execute_reply":"2023-12-01T13:54:07.591600Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Skipping product description as it's too lengthy and missing values\ntrain = clean_train_1\ntrain_input = train.apply(lambda x: x['query']+' '+x['product_title'], axis=1)\ndev_input =  dev.apply(lambda x: x['query']+' '+x['product_title'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T13:54:07.593789Z","iopub.execute_input":"2023-12-01T13:54:07.594119Z","iopub.status.idle":"2023-12-01T13:54:07.758676Z","shell.execute_reply.started":"2023-12-01T13:54:07.594075Z","shell.execute_reply":"2023-12-01T13:54:07.757658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer \ntfidf = TfidfVectorizer(ngram_range=(1, 5),stop_words = 'english', strip_accents='unicode')\ntrain_x = tfidf.fit_transform(train_input)\ndev_x = tfidf.transform(dev_input)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T13:54:07.759890Z","iopub.execute_input":"2023-12-01T13:54:07.760133Z","iopub.status.idle":"2023-12-01T13:54:08.861852Z","shell.execute_reply.started":"2023-12-01T13:54:07.760104Z","shell.execute_reply":"2023-12-01T13:54:08.861016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_y, dev_y = train.median_relevance.to_list(), dev.median_relevance.to_list()\ntrain_y = [(x-1)/3 for x in train_y]\ndev_y = [(x-1)/3 for x in dev_y]\nnp.mean(train_y), np.max(train_y), np.min(train_y)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T13:54:08.863203Z","iopub.execute_input":"2023-12-01T13:54:08.864086Z","iopub.status.idle":"2023-12-01T13:54:08.878150Z","shell.execute_reply.started":"2023-12-01T13:54:08.864043Z","shell.execute_reply":"2023-12-01T13:54:08.877075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import datetime\ncurrent_time = datetime.datetime.now()\nformatted_time = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\ntime = f\"{formatted_time}\"","metadata":{"execution":{"iopub.status.busy":"2023-12-01T13:54:08.879497Z","iopub.execute_input":"2023-12-01T13:54:08.880175Z","iopub.status.idle":"2023-12-01T13:54:08.884614Z","shell.execute_reply.started":"2023-12-01T13:54:08.880137Z","shell.execute_reply":"2023-12-01T13:54:08.883663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport wandb\nfrom wandb.keras import WandbCallback\nos.system('! wandb login be213aaff4ff14945d480abc18697d8664bba8c8')","metadata":{"execution":{"iopub.status.busy":"2023-12-01T13:54:08.885956Z","iopub.execute_input":"2023-12-01T13:54:08.886383Z","iopub.status.idle":"2023-12-01T13:54:10.914029Z","shell.execute_reply.started":"2023-12-01T13:54:08.886336Z","shell.execute_reply":"2023-12-01T13:54:10.912830Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, cohen_kappa_score, make_scorer\ndef reg_scorer(true, pred):\n    pred = [min(1, max(0,x)) for x in pred]\n    pred = [int(round((x*3)+1)) for x in pred]\n    true = [int(round((x*3)+1)) for x in true]\n    return cohen_kappa_score(true, pred)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T13:54:10.916117Z","iopub.execute_input":"2023-12-01T13:54:10.916420Z","iopub.status.idle":"2023-12-01T13:54:10.922947Z","shell.execute_reply.started":"2023-12-01T13:54:10.916363Z","shell.execute_reply":"2023-12-01T13:54:10.922002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.init(project='CrowdflowerModelsOnly', name='figuring out params '+time)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T13:54:10.924442Z","iopub.execute_input":"2023-12-01T13:54:10.924935Z","iopub.status.idle":"2023-12-01T13:54:17.775623Z","shell.execute_reply.started":"2023-12-01T13:54:10.924899Z","shell.execute_reply":"2023-12-01T13:54:17.774777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression, SGDRegressor\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVR\n#clf = LinearRegression().fit(train_x, train_y)\n#clf = SGDRegressor(verbose=1,n_iter_no_change=20).fit(train_x, train_y)\n'''param_grid = {'C': [1], 'epsilon':[0.1,0.05], 'kernel': ('linear', 'rbf')}\nsvr  = SVR()\nscorer = make_scorer(reg_scorer, greater_is_better=True)\nclf = GridSearchCV(svr, param_grid, verbose=True,scoring=scorer, n_jobs=8)\nclf.fit(train_x, train_y)\nclf.best_estimator_, clf.best_params_, clf.best_score_'''","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-12-01T13:54:17.777388Z","iopub.execute_input":"2023-12-01T13:54:17.777698Z","iopub.status.idle":"2023-12-01T13:54:17.784502Z","shell.execute_reply.started":"2023-12-01T13:54:17.777658Z","shell.execute_reply":"2023-12-01T13:54:17.783881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## 0.26 is the best score till now\n\n#preds = clf.best_estimator_.predict(dev_x)\n#mean_squared_error(dev_y, preds),  reg_scorer(dev_y, preds)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T13:54:17.785820Z","iopub.execute_input":"2023-12-01T13:54:17.786277Z","iopub.status.idle":"2023-12-01T13:54:17.796295Z","shell.execute_reply.started":"2023-12-01T13:54:17.786243Z","shell.execute_reply":"2023-12-01T13:54:17.795467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scorer = make_scorer(reg_scorer, greater_is_better=True)\n\n#GridSearch\n'''from sklearn.ensemble import StackingRegressor, RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.svm import SVR\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.metrics import make_scorer, mean_squared_error\nfrom sklearn.utils import check_random_state\n\nX_train, X_dev, y_train, y_dev = train_test_split(train_x, train_y, test_size=0.2, random_state=42)\n\n# Define base models\nsvr = SVR()\nrf = RandomForestRegressor()\ngb = GradientBoostingRegressor()\n\n\nmeta_model = LinearRegression()\n\n\n\n# Perform GridSearchCV for each base model\n'''\nparam_grid_svr = {'C': [0.1], 'epsilon': [0.01, 0.05], 'kernel': ['linear', 'rbf']}\nparam_grid_rf = {'n_estimators': [50, 200], 'max_depth': [None, 10]}\nparam_grid_gb = {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 0.2]}\n\n'''\n\nparam_grid_svr = {'C': [0.1], 'epsilon': [0.01, 0.05], 'kernel': ['linear', 'rbf']}\nparam_grid_rf = {'n_estimators': [50], 'max_depth': [10]}\nparam_grid_gb = {'n_estimators': [100], 'learning_rate': [0.05]}\n\ngrid_search_svr = GridSearchCV(svr, param_grid_svr, verbose=True, scoring=scorer, n_jobs=-1)\ngrid_search_rf = GridSearchCV(rf, param_grid_rf, verbose=True, scoring=scorer, n_jobs=-1)\ngrid_search_gb = GridSearchCV(gb, param_grid_gb, verbose=True, scoring=scorer, n_jobs=-1)\n\ngrid_search_svr.fit(X_train, y_train)\ngrid_search_rf.fit(X_train, y_train)\ngrid_search_gb.fit(X_train, y_train)\n\n# Get best estimators\nsvr_best_estimator = grid_search_svr.best_estimator_\nrf_best_estimator = grid_search_rf.best_estimator_\ngb_best_estimator = grid_search_gb.best_estimator_\n'''\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-01T13:54:17.797860Z","iopub.execute_input":"2023-12-01T13:54:17.798373Z","iopub.status.idle":"2023-12-01T13:54:17.811351Z","shell.execute_reply.started":"2023-12-01T13:54:17.798337Z","shell.execute_reply":"2023-12-01T13:54:17.810472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''# Define stacking regressor with cross-validated predictions\nstacked_reg = StackingRegressor(\n    estimators=[('svr', svr), ('rf', rf), ('gb', gb)],\n    final_estimator=meta_model,\n    cv=5  \n)'''\n'''stacked_reg = StackingRegressor(\n    estimators=[('svr', grid_search_svr.best_estimator_),\n                ('rf', grid_search_rf.best_estimator_),\n                ('gb', grid_search_gb.best_estimator_)],\n    final_estimator=meta_model,\n    cv=5  # 5-fold cross-validation for stacking\n)\n# Fit the stacking regressor with the best base models\nstacked_reg.fit(X_train, y_train)\n\n# Evaluate on the validation set\ny_pred_stacked = stacked_reg.predict(X_dev)\nmse_stacked = mean_squared_error(y_dev, y_pred_stacked)\nprint(f'Mean Squared Error for Stacked Ensemble: {mse_stacked}')'''","metadata":{"execution":{"iopub.status.busy":"2023-12-01T13:54:17.813099Z","iopub.execute_input":"2023-12-01T13:54:17.813611Z","iopub.status.idle":"2023-12-01T13:54:17.827533Z","shell.execute_reply.started":"2023-12-01T13:54:17.813574Z","shell.execute_reply":"2023-12-01T13:54:17.826630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import StackingRegressor, RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.linear_model import LinearRegression, Lasso\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.model_selection import RandomizedSearchCV, train_test_split\nfrom sklearn.metrics import make_scorer, mean_squared_error\nfrom scipy.stats import randint, uniform\n\n# Assuming you have train_x, train_y as your training data\nX_train, X_dev, y_train, y_dev = train_test_split(train_x, train_y, test_size=0.2, random_state=42)\n\n# Define base models\nsvr = SVR()\nrf = RandomForestRegressor()\ngb = GradientBoostingRegressor()\nknn = KNeighborsRegressor()\nlasso = Lasso()\n\n# Define meta-model\nmeta_model = LinearRegression()\n\n# Define parameter distributions for RandomizedSearchCV\n#param_dist_svr = {'C': uniform(0.1, 1.0), 'epsilon': uniform(0.01, 0.1), 'kernel': ['linear', 'rbf']}\nparam_grid_svr = {'C': [0.1], 'epsilon': [0.01, 0.05], 'kernel': ['linear', 'rbf']}\n\n#updated grid\n'''param_grid = {\n    'estimator__C': [0.001, 0.01, 0.1],\n    'estimator__kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n    'estimator__gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1, 10],\n    'estimator__epsilon': [0.01, 0.05],\n    'estimator__degree': [2, 3, 4, 5],\n    'estimator__coef0': [0.0, 0.1, 0.5, 1.0],\n    'estimator__shrinking': [True, False],\n    'estimator__max_iter': [-1, 100, 500, 1000],\n}'''\n\nparam_dist_rf = {'n_estimators': randint(50, 200), 'max_depth': [None, 10, 20]}\nparam_dist_gb = {'n_estimators': randint(50, 200), 'learning_rate': uniform(0.01, 0.2)}\nparam_dist_knn = {'n_neighbors': randint(1, 10), 'weights': ['uniform', 'distance']}\nparam_dist_lasso = {'alpha': uniform(0.1, 1.0)}\n\n# Perform RandomizedSearchCV for each base model\n#random_search_svr = RandomizedSearchCV(svr, param_distributions=param_dist_svr, n_iter=5, verbose=True, scoring=scorer, n_jobs=-1)\ngrid_search_svr = GridSearchCV(svr, param_grid_svr, verbose=True, scoring=scorer, cv=5, n_jobs=-1)\n###\n\ngrid_search_svr.fit(X_train, y_train)\n\ny_pred_svr = grid_search_svr.predict(X_dev)\nmse_svr = mean_squared_error(y_dev, y_pred_svr)\n#wandb.log(grid_search_svr.get_params())\n#wandb.sklearn.log_model(grid_search_svr)\nsvr_params = grid_search_svr.get_params()\nmodels = {\n    \"SVR\": {\n        \"model\": grid_search_svr,\n        \"params\": svr_params,\n        \"score\" : mse_svr,\n        \"best estimator\": grid_search_svr.best_estimator_\n    },\n    \"SVR\": {\n        \"model\": grid_search_svr,\n        \"params\": svr_params,\n        \"score\" : mse_svr\n    }\n}\nwandb.config.update(models)\n\nwandb.finish()\n\ntest_input =  test.apply(lambda x: x['query']+' '+x['product_title'], axis=1)\ntest_x = tfidf.transform(test_input)\npred = grid_search_svr.best_estimator_.predict(test_x)\npred = [min(1, max(0,x)) for x in pred]\npred = [int(round((x*3)+1)) for x in pred]\nout = pd.DataFrame({\"id\": test.id.to_list(), \"prediction\": pred})\nout.to_csv('submission.csv', index=False)\n\n####\n\n'''random_search_rf = RandomizedSearchCV(rf, param_distributions=param_dist_rf, n_iter=5, verbose=True, scoring=scorer, n_jobs=-1)\nrandom_search_gb = RandomizedSearchCV(gb, param_distributions=param_dist_gb, n_iter=5, verbose=True, scoring=scorer, n_jobs=-1)\nrandom_search_knn = RandomizedSearchCV(knn, param_distributions=param_dist_knn, n_iter=5, verbose=True, scoring=scorer, n_jobs=-1)\nrandom_search_lasso = RandomizedSearchCV(lasso, param_distributions=param_dist_lasso, n_iter=5, verbose=True, scoring=scorer, n_jobs=-1)\n\n#random_search_svr.fit(X_train, y_train)\ngrid_search_svr.fit(X_train, y_train)\nrandom_search_rf.fit(X_train, y_train)\nrandom_search_gb.fit(X_train, y_train)\nrandom_search_knn.fit(X_train, y_train)\nrandom_search_lasso.fit(X_train, y_train)'''\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-01T13:54:17.830148Z","iopub.execute_input":"2023-12-01T13:54:17.831025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_search_svr.get_params()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''y_pred_svr = grid_search_svr.predict(X_dev)\nmse_svr = mean_squared_error(y_dev, y_pred_svr)\n#wandb.log(grid_search_svr.get_params())\n#wandb.sklearn.log_model(grid_search_svr)\nsvr_params = grid_search_svr.get_params()\nmodels = {\n    \"SVR\": {\n        \"model\": grid_search_svr,\n        \"params\": svr_params,\n        \"score\" : mse_svr\n    },\n    \"SVR\": {\n        \"model\": grid_search_svr,\n        \"params\": svr_params,\n        \"score\" : mse_svr\n    }\n}\nwandb.config.update(models)\n#wandb.log(mse_svr)'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''weights = {'svr': 2.0, 'rf': 0.5, 'gb': 1.0, 'knn': 1.0, 'lasso': 1.0}\n#apparently we cant use weights here\n\nstacked_reg = StackingRegressor(\n    estimators=[\n        ('svr', grid_search_svr.best_estimator_),\n        #('rf', random_search_rf.best_estimator_),\n        ('gb', random_search_gb.best_estimator_),\n        ('knn', random_search_knn.best_estimator_),\n        ('lasso', random_search_lasso.best_estimator_)\n    ],\n    final_estimator=meta_model,\n    cv = 5,\n    n_jobs=-1,\n    passthrough=True,\n    #weights=[weights[model_name] for model_name, _ in [('svr', svr), ('rf', rf), ('gb', gb), ('knn', knn), ('lasso', lasso)]]\n)\n\n# Fit the stacking regressor with the best base models\nstacked_reg.fit(X_train, y_train)\n\n# Evaluate on the validation set\ny_pred_stacked = stacked_reg.predict(X_dev)\nmse_stacked = mean_squared_error(y_dev, y_pred_stacked)\nprint(f'Mean Squared Error for Stacked Ensemble: {mse_stacked}')'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''test_input =  test.apply(lambda x: x['query']+' '+x['product_title'], axis=1)\ntest_x = tfidf.transform(test_input)\npred = stacked_reg.predict(test_x)\npred = [min(1, max(0,x)) for x in pred]\npred = [int(round((x*3)+1)) for x in pred]\nout = pd.DataFrame({\"id\": test.id.to_list(), \"prediction\": pred})\nout.to_csv('submission.csv', index=False)'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv('/kaggle/input/crowdflower-search-relevance/sampleSubmission.csv.zip')\nsub\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.finish()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}